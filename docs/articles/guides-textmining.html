<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Text mining with Spark &amp; sparklyr • sparklyr</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">sparklyr</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">Home</a>
</li>
<li>
  <a href="../articles/gallery.html">Gallery</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Guides
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/guides-dplyr.html">dplyr</a>
    </li>
    <li>
      <a href="../articles/guides-mllib.html">mllib</a>
    </li>
    <li>
      <a href="../articles/guides-distributed-r.html">Distributed R</a>
    </li>
    <li>
      <a href="../articles/guides-extensions.html">Extensions</a>
    </li>
    <li>
      <a href="../articles/guides-caching.html">Caching</a>
    </li>
    <li>
      <a href="../articles/guides-h2o.html">H2O</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Deployment
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/deployment-overview.html">Overview</a>
    </li>
    <li>
      <a href="../articles/deployment-data-lakes.html">Data Lakes</a>
    </li>
    <li>
      <a href="../articles/deployment-cdh.html">Cloudera</a>
    </li>
    <li>
      <a href="../articles/deployment-amazon.html">Amazon</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Reference
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../reference/index.html">Functions</a>
    </li>
    <li>
      <a href="https://github.com/rstudio/cheatsheets/raw/master/source/pdfs/sparklyr-cheatsheet.pdf">Cheatsheet</a>
    </li>
    <li>
      <a href="../articles/reference-media.html">Media</a>
    </li>
    <li>
      <a href="../news/index.html">News</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/rstudio/sparklyr">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>Text mining with Spark &amp; sparklyr</h1>
            
          </div>

    
    
<div class="contents">
<p>This article focuses on a set of functions that can be used for text mining with Spark and <code>sparklyr</code>. The main goal is to illustrate how to perform most of the data preparation and analysis with commands that will run inside the Spark cluster, as opposed to locally in R. Because of that, the amount of data used will be small.</p>
<div id="connect-to-spark" class="section level2">
<h2 class="hasAnchor">
<a href="#connect-to-spark" class="anchor"></a>Connect to Spark</h2>
<p>An additional goal of this article is to encourage the reader to try it out, so a simple Spark local mode session is used.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(sparklyr)
<span class="kw">library</span>(dplyr)

sc &lt;-<span class="st"> </span><span class="kw"><a href="../reference/spark-connections.html">spark_connect</a></span>(<span class="dt">master =</span> <span class="st">"local"</span>, <span class="dt">version =</span> <span class="st">"2.1.0"</span>)</code></pre></div>
<div id="data-source" class="section level3">
<h3 class="hasAnchor">
<a href="#data-source" class="anchor"></a>Data source</h3>
<p>For this example, there are two files that will be analyzed. They are both the full works of Sir Arthur Conan Doyle and Mark Twain. The files were downloaded from the <a href="https://www.gutenberg.org/">Gutenberg Project</a> site via the <code>gutenbergr</code> package. Intentionally, no data cleanup was done to the files prior to this analysis. See the appendix below to see how the data was downloaded and prepared.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">readLines</span>(<span class="st">"arthur_doyle.txt"</span>, <span class="dv">10</span>) </code></pre></div>
<pre><code>##  [1] "THE RETURN OF SHERLOCK HOLMES,"   
##  [2] ""                                 
##  [3] "A Collection of Holmes Adventures"
##  [4] ""                                 
##  [5] ""                                 
##  [6] "by Sir Arthur Conan Doyle"        
##  [7] ""                                 
##  [8] ""                                 
##  [9] ""                                 
## [10] ""</code></pre>
</div>
</div>
<div id="data-import" class="section level2">
<h2 class="hasAnchor">
<a href="#data-import" class="anchor"></a>Data Import</h2>
<div id="spark_read_text" class="section level3">
<h3 class="hasAnchor">
<a href="#spark_read_text" class="anchor"></a>spark_read_text()</h3>
<p>The <code><a href="../reference/spark_read_text.html">spark_read_text()</a></code> is a new function which works like <code>readLines()</code> but for <code>sparklyr</code>. It comes in handy when non-structured data, such as lines in a book, is what is available for analysis.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Imports Mark Twain's file</span>

<span class="co"># Setting up the path to the file in a Windows OS laptop</span>
twain_path &lt;-<span class="st"> </span><span class="kw">paste0</span>(<span class="st">"file:///"</span>, <span class="kw">getwd</span>(), <span class="st">"/mark_twain.txt"</span>)
twain &lt;-<span class="st">  </span><span class="kw"><a href="../reference/spark_read_text.html">spark_read_text</a></span>(sc, <span class="st">"twain"</span>, twain_path) </code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Imports Sir Arthur Conan Doyle's file</span>
doyle_path &lt;-<span class="st"> </span><span class="kw">paste0</span>(<span class="st">"file:///"</span>, <span class="kw">getwd</span>(), <span class="st">"/arthur_doyle.txt"</span>)
doyle &lt;-<span class="st">  </span><span class="kw"><a href="../reference/spark_read_text.html">spark_read_text</a></span>(sc, <span class="st">"doyle"</span>, doyle_path) </code></pre></div>
</div>
</div>
<div id="data-transformation" class="section level2">
<h2 class="hasAnchor">
<a href="#data-transformation" class="anchor"></a>Data transformation</h2>
<p>The objective is to end up with a tidy table inside Spark with one row per word used. The steps will be:</p>
<ol style="list-style-type: decimal">
<li>The needed data transformations apply to the data from both authors. The data sets will be appended to one another</li>
<li>Punctuation will be removed</li>
<li>The words inside each line will be separated, or tokenized</li>
<li>For a cleaner analysis, stop words will be removed</li>
<li>To tidy the data, each word in a line will become its own row</li>
<li>The results will be saved to Spark memory</li>
</ol>
<div id="sdf_bind_rows" class="section level3">
<h3 class="hasAnchor">
<a href="#sdf_bind_rows" class="anchor"></a>sdf_bind_rows()</h3>
<ul>
<li>
<code><a href="../reference/sdf_bind.html">sdf_bind_rows()</a></code> appends the <code>doyle</code> Spark Dataframe to the <code>twain</code> Spark Dataframe. This function can be used in lieu of a <code><a href="http://dplyr.tidyverse.org/reference/bind.html">dplyr::bind_rows()</a></code> wrapper function. For this exercise, the column <code>author</code> is added to differentiate between the two bodies of work.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">all_words &lt;-<span class="st"> </span>doyle <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">author =</span> <span class="st">"doyle"</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="../reference/sdf_bind.html">sdf_bind_rows</a></span>({
    twain <span class="op">%&gt;%</span>
<span class="st">      </span><span class="kw">mutate</span>(<span class="dt">author =</span> <span class="st">"twain"</span>)}) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(<span class="kw">nchar</span>(line) <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>)</code></pre></div>
</div>
<div id="regexp_replace" class="section level3">
<h3 class="hasAnchor">
<a href="#regexp_replace" class="anchor"></a>regexp_replace</h3>
<ul>
<li>The Hive UDF, <strong>regexp_replace</strong>, is used as a sort of <code>gsub()</code> that works inside Spark. In this case it is used to remove punctuation. The usual <code>[:punct:]</code> regular expression did not work well during development, so a custom list is provided. For more information, see the <a href="https://spark.rstudio.com/articles/guides-dplyr.html#hive-functions">Hive Functions</a> section in the <code>dplyr</code> page.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">all_words &lt;-<span class="st"> </span>all_words <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">line =</span> <span class="kw">regexp_replace</span>(line, <span class="st">"[_</span><span class="ch">\"\'</span><span class="st">():;,.!?</span><span class="ch">\\</span><span class="st">-]"</span>, <span class="st">" "</span>)) </code></pre></div>
</div>
<div id="ft_tokenizer" class="section level3">
<h3 class="hasAnchor">
<a href="#ft_tokenizer" class="anchor"></a>ft_tokenizer()</h3>
<ul>
<li>
<code><a href="../reference/ft_tokenizer.html">ft_tokenizer()</a></code> uses the Spark API to separate each word. It creates a new list column with the results.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">all_words &lt;-<span class="st"> </span>all_words <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw"><a href="../reference/ft_tokenizer.html">ft_tokenizer</a></span>(<span class="dt">input.col =</span> <span class="st">"line"</span>,
               <span class="dt">output.col =</span> <span class="st">"word_list"</span>)

<span class="kw">head</span>(all_words, <span class="dv">4</span>)</code></pre></div>
<pre><code>## # Source:   lazy query [?? x 3]
## # Database: spark_connection
##   author                              line  word_list
##    &lt;chr&gt;                             &lt;chr&gt;     &lt;list&gt;
## 1  doyle    THE RETURN OF SHERLOCK HOLMES  &lt;list [5]&gt;
## 2  doyle A Collection of Holmes Adventures &lt;list [5]&gt;
## 3  doyle         by Sir Arthur Conan Doyle &lt;list [5]&gt;
## 4  doyle                         CONTENTS  &lt;list [1]&gt;</code></pre>
</div>
<div id="ft_stop_words_remover" class="section level3">
<h3 class="hasAnchor">
<a href="#ft_stop_words_remover" class="anchor"></a>ft_stop_words_remover()</h3>
<ul>
<li>
<code>ft_stop_words_remover()</code> is a new function that, as its name suggests, takes care of removing stop words from the previous transformation. It expects a list column, so it is important to sequence it correctly after a <code><a href="../reference/ft_tokenizer.html">ft_tokenizer()</a></code> command. In the sample results, notice that the new <code>wo_stop_words</code> column contains less items than <code>word_list</code>.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">all_words &lt;-<span class="st"> </span>all_words <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ft_stop_words_remover</span>(<span class="dt">input.col =</span> <span class="st">"word_list"</span>,
                        <span class="dt">output.col =</span> <span class="st">"wo_stop_words"</span>)

<span class="kw">head</span>(all_words, <span class="dv">4</span>)</code></pre></div>
<pre><code>## # Source:   lazy query [?? x 4]
## # Database: spark_connection
##   author                              line  word_list wo_stop_words
##    &lt;chr&gt;                             &lt;chr&gt;     &lt;list&gt;        &lt;list&gt;
## 1  doyle    THE RETURN OF SHERLOCK HOLMES  &lt;list [5]&gt;    &lt;list [3]&gt;
## 2  doyle A Collection of Holmes Adventures &lt;list [5]&gt;    &lt;list [3]&gt;
## 3  doyle         by Sir Arthur Conan Doyle &lt;list [5]&gt;    &lt;list [4]&gt;
## 4  doyle                         CONTENTS  &lt;list [1]&gt;    &lt;list [1]&gt;</code></pre>
</div>
<div id="explode" class="section level3">
<h3 class="hasAnchor">
<a href="#explode" class="anchor"></a>explode</h3>
<ul>
<li>The Hive UDF <strong>explode</strong> performs the job of unnesting the tokens into their own row. Some further filtering and field selection is done to reduce the size of the dataset.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">all_words &lt;-<span class="st"> </span>all_words <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">word =</span> <span class="kw">explode</span>(wo_stop_words)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(word, author) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(<span class="kw">nchar</span>(word) <span class="op">&gt;</span><span class="st"> </span><span class="dv">2</span>)
  
<span class="kw">head</span>(all_words, <span class="dv">4</span>)</code></pre></div>
<pre><code>## # Source:   lazy query [?? x 2]
## # Database: spark_connection
##         word author
##        &lt;chr&gt;  &lt;chr&gt;
## 1     return  doyle
## 2   sherlock  doyle
## 3     holmes  doyle
## 4 collection  doyle</code></pre>
</div>
<div id="compute" class="section level3">
<h3 class="hasAnchor">
<a href="#compute" class="anchor"></a>compute()</h3>
<ul>
<li>
<code>compute()</code> will operate this transformation and cache the results in Spark memory. It is a good idea to pass a name to <code>compute()</code> to make it easier to identify it inside the Spark environment. In this case the name will be <em>all_words</em>
</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">all_words &lt;-<span class="st"> </span>all_words <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">compute</span>(<span class="st">"all_words"</span>)</code></pre></div>
</div>
</div>
<div id="full-code" class="section level2">
<h2 class="hasAnchor">
<a href="#full-code" class="anchor"></a>Full code</h2>
<p>This is what the code would look like on an actual analysis:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">all_words &lt;-<span class="st"> </span>doyle <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">author =</span> <span class="st">"doyle"</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="../reference/sdf_bind.html">sdf_bind_rows</a></span>({
    twain <span class="op">%&gt;%</span>
<span class="st">      </span><span class="kw">mutate</span>(<span class="dt">author =</span> <span class="st">"twain"</span>)}) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(<span class="kw">nchar</span>(line) <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">line =</span> <span class="kw">regexp_replace</span>(line, <span class="st">"[_</span><span class="ch">\"\'</span><span class="st">():;,.!?</span><span class="ch">\\</span><span class="st">-]"</span>, <span class="st">" "</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="../reference/ft_tokenizer.html">ft_tokenizer</a></span>(<span class="dt">input.col =</span> <span class="st">"line"</span>,
               <span class="dt">output.col =</span> <span class="st">"word_list"</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ft_stop_words_remover</span>(<span class="dt">input.col =</span> <span class="st">"word_list"</span>,
                        <span class="dt">output.col =</span> <span class="st">"wo_stop_words"</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">word =</span> <span class="kw">explode</span>(wo_stop_words)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(word, author) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(<span class="kw">nchar</span>(word) <span class="op">&gt;</span><span class="st"> </span><span class="dv">2</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">compute</span>(<span class="st">"all_words"</span>)</code></pre></div>
</div>
<div id="data-analysis" class="section level2">
<h2 class="hasAnchor">
<a href="#data-analysis" class="anchor"></a>Data Analysis</h2>
<div id="words-used-the-most" class="section level3">
<h3 class="hasAnchor">
<a href="#words-used-the-most" class="anchor"></a>Words used the most</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">word_count &lt;-<span class="st"> </span>all_words <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(author, word) <span class="op">%&gt;%</span>
<span class="st">  </span>tally <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(n)) 
  
word_count</code></pre></div>
<pre><code>## # Source:     lazy query [?? x 3]
## # Database:   spark_connection
## # Groups:     author
## # Ordered by: desc(n)
##    author  word     n
##     &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;
##  1  twain   one 20028
##  2  doyle  upon 16482
##  3  twain would 15735
##  4  doyle   one 14534
##  5  doyle  said 13716
##  6  twain  said 13204
##  7  twain could 11301
##  8  doyle would 11300
##  9  twain  time 10502
## 10  doyle   man 10478
## # ... with more rows</code></pre>
</div>
<div id="words-used-by-doyle-and-not-twain" class="section level3">
<h3 class="hasAnchor">
<a href="#words-used-by-doyle-and-not-twain" class="anchor"></a>Words used by Doyle and not Twain</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">doyle_unique &lt;-<span class="st"> </span><span class="kw">filter</span>(word_count, author <span class="op">==</span><span class="st"> "doyle"</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">anti_join</span>(<span class="kw">filter</span>(word_count, author <span class="op">==</span><span class="st"> "twain"</span>), <span class="dt">by =</span> <span class="st">"word"</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(n)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">compute</span>(<span class="st">"doyle_unique"</span>)

doyle_unique</code></pre></div>
<pre><code>## # Source:     lazy query [?? x 3]
## # Database:   spark_connection
## # Groups:     author
## # Ordered by: desc(n), desc(n)
##    author      word     n
##     &lt;chr&gt;     &lt;chr&gt; &lt;dbl&gt;
##  1  doyle     nigel   972
##  2  doyle   alleyne   500
##  3  doyle      ezra   421
##  4  doyle     maude   337
##  5  doyle   aylward   336
##  6  doyle   catinat   301
##  7  doyle   sharkey   281
##  8  doyle  lestrade   280
##  9  doyle summerlee   248
## 10  doyle     congo   211
## # ... with more rows</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">doyle_unique <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">head</span>(<span class="dv">100</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">collect</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">with</span>(wordcloud<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/wordcloud/topics/wordcloud">wordcloud</a></span>(
    word, 
    n,
    <span class="dt">colors =</span> <span class="kw">c</span>(<span class="st">"#999999"</span>, <span class="st">"#E69F00"</span>, <span class="st">"#56B4E9"</span>,<span class="st">"#56B4E9"</span>)))</code></pre></div>
<p><img src="guides-textmining_files/figure-html/unnamed-chunk-14-1.png" width="672"></p>
</div>
<div id="twain-and-sherlock" class="section level3">
<h3 class="hasAnchor">
<a href="#twain-and-sherlock" class="anchor"></a>Twain and Sherlock</h3>
<p>The word cloud highlighted something interesting. The word <strong>lestrade</strong> is listed as one of the words used by Doyle but not Twain. Lestrade is the last name of a major character in the Sherlock Holmes books. It makes sense that the word “sherlock” appears considerably more times than “lestrade” in Doyle’s books, so why is Sherlock not in the word cloud? Did Mark Twain use the word “sherlock” in his writings?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">all_words <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(author <span class="op">==</span><span class="st"> "twain"</span>,
         word <span class="op">==</span><span class="st"> "sherlock"</span>) <span class="op">%&gt;%</span>
<span class="st">  </span>tally</code></pre></div>
<pre><code>## # Source:   lazy query [?? x 1]
## # Database: spark_connection
##       n
##   &lt;dbl&gt;
## 1    16</code></pre>
<p>The <code>all_words</code> table <strong>contains 16 instances</strong> of the word <strong>sherlock</strong> in the words used by Twain in his works. The <strong>instr</strong> Hive UDF is used to extract the lines that contain that word in the <code>twain</code> table. This Hive function works can be used instead of <code><a href="http://www.rdocumentation.org/packages/base/topics/grep">base::grep()</a></code> or <code><a href="http://www.rdocumentation.org/packages/stringr/topics/str_detect">stringr::str_detect()</a></code>. To account for any word capitalization, the <strong>lower</strong> command will be used in <code>mutate()</code> to make all words in the full text lower cap.</p>
</div>
<div id="instr-lower" class="section level3">
<h3 class="hasAnchor">
<a href="#instr-lower" class="anchor"></a>instr &amp; lower</h3>
<p>Most of these lines are in a short story by Mark Twain called <a href="https://www.gutenberg.org/files/3180/3180-h/3180-h.htm#link2H_4_0008">A Doudle Barrelled Detective Story</a>. As per the <a href="https://en.wikipedia.org/wiki/A_Double_Barrelled_Detective_Story">Wikipedia</a> page about this story, this is a satire by Twain on the mystery novel genre, published in 1902.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">twain <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">line =</span> <span class="kw">lower</span>(line)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(<span class="kw">instr</span>(line, <span class="st">"sherlock"</span>) <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">pull</span>(line)</code></pre></div>
<pre><code>##  [1] "late sherlock holmes, and yet discernible by a member of a race charged"  
##  [2] "sherlock holmes."                                                         
##  [3] "\"uncle sherlock! the mean luck of it!--that he should come just"         
##  [4] "another trouble presented itself. \"uncle sherlock 'll be wanting to talk"
##  [5] "flint buckner's cabin in the frosty gloom. they were sherlock holmes and" 
##  [6] "\"uncle sherlock's got some work to do, gentlemen, that 'll keep him till"
##  [7] "\"by george, he's just a duke, boys! three cheers for sherlock holmes,"   
##  [8] "he brought sherlock holmes to the billiard-room, which was jammed with"   
##  [9] "of interest was there--sherlock holmes. the miners stood silent and"      
## [10] "the room; the chair was on it; sherlock holmes, stately, imposing,"       
## [11] "\"you have hunted me around the world, sherlock holmes, yet god is my"    
## [12] "\"if it's only sherlock holmes that's troubling you, you needn't worry"   
## [13] "they sighed; then one said: \"we must bring sherlock holmes. he can be"   
## [14] "i had small desire that sherlock holmes should hang for my deeds, as you" 
## [15] "\"my name is sherlock holmes, and i have not been doing anything.\""      
## [16] "late sherlock holmes, and yet discernible by a member of a race charged"</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/spark-connections.html">spark_disconnect</a></span>(sc)</code></pre></div>
</div>
</div>
<div id="appendix" class="section level2">
<h2 class="hasAnchor">
<a href="#appendix" class="anchor"></a>Appendix</h2>
<div id="gutenbergr-package" class="section level3">
<h3 class="hasAnchor">
<a href="#gutenbergr-package" class="anchor"></a>gutenbergr package</h3>
<p>This is an example of how the data for this article was pulled from the Gutenberg site:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(gutenbergr)

<span class="kw">gutenberg_works</span>()  <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(author <span class="op">==</span><span class="st"> "Twain, Mark"</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">pull</span>(gutenberg_id) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gutenberg_download</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">pull</span>(text) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">writeLines</span>(<span class="st">"mark_twain.txt"</span>)</code></pre></div>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#connect-to-spark">Connect to Spark</a></li>
      <li><a href="#data-import">Data Import</a></li>
      <li><a href="#data-transformation">Data transformation</a></li>
      <li><a href="#full-code">Full code</a></li>
      <li><a href="#data-analysis">Data Analysis</a></li>
      <li><a href="#appendix">Appendix</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Javier Luraschi, Kevin Ushey, JJ Allaire,  The Apache Software Foundation.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
