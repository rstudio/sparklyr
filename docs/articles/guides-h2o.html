<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Sparkling Water (H2O) Machine Learning • sparklyr</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">sparklyr</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">Home</a>
</li>
<li>
  <a href="../articles/gallery.html">Gallery</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Guides
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/guides-dplyr.html">dplyr</a>
    </li>
    <li>
      <a href="../articles/guides-mllib.html">mllib</a>
    </li>
    <li>
      <a href="../articles/guides-distributed-r.html">Distributed R</a>
    </li>
    <li>
      <a href="../articles/guides-extensions.html">Extensions</a>
    </li>
    <li>
      <a href="../articles/guides-caching.html">Caching</a>
    </li>
    <li>
      <a href="../articles/guides-h2o.html">H2O</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Deployment
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/deployment-overview.html">Overview</a>
    </li>
    <li>
      <a href="../articles/deployment-data-lakes.html">Data Lakes</a>
    </li>
    <li>
      <a href="../articles/deployment-cdh.html">Cloudera</a>
    </li>
    <li>
      <a href="../articles/deployment-amazon.html">Amazon</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Reference
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../reference/index.html">Functions</a>
    </li>
    <li>
      <a href="https://github.com/rstudio/cheatsheets/raw/master/source/pdfs/sparklyr-cheatsheet.pdf">Cheatsheet</a>
    </li>
    <li>
      <a href="../articles/reference-media.html">Media</a>
    </li>
    <li>
      <a href="../news/index.html">News</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/rstudio/sparklyr">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>Sparkling Water (H2O) Machine Learning</h1>
            
          </div>

    
    
<div class="contents">
<div id="overview" class="section level2">
<h2 class="hasAnchor">
<a href="#overview" class="anchor"></a>Overview</h2>
<p>The <strong>rsparkling</strong> extension package provides bindings to H2O’s distributed <a href="http://www.h2o.ai/product/algorithms/">machine learning</a> algorithms via <strong>sparklyr</strong>. In particular, rsparkling allows you to access the machine learning routines provided by the <a href="http://www.h2o.ai/product/sparkling-water/">Sparkling Water</a> Spark package.</p>
<p>Together with sparklyr’s <a href="dplyr.html">dplyr</a> interface, you can easily create and tune H2O machine learning workflows on Spark, orchestrated entirely within R.</p>
<p><a href="https://github.com/h2oai/rsparkling">rsparkling</a> provides a few simple conversion functions that allow the user to transfer data between Spark DataFrames and H2O Frames. Once the Spark DataFrames are available as H2O Frames, the <strong>h2o</strong> R interface can be used to train H2O machine learning algorithms on the data.</p>
<p>A typical machine learning pipeline with rsparkling might be composed of the following stages. To fit a model, you might need to:</p>
<ol style="list-style-type: decimal">
<li>Perform SQL queries through the sparklyr <a href="dplyr.html">dplyr</a> interface,</li>
<li>Use the <code>sdf_*</code> and <code>ft_*</code> family of functions to generate new columns, or partition your data set,</li>
<li>Convert your training, validation and/or test data frames into H2O Frames using the <code>as_h2o_frame</code> function,</li>
<li>Choose an appropriate H2O machine learning algorithm to model your data,</li>
<li>Inspect the quality of your model fit, and use it to make predictions with new data.</li>
</ol>
</div>
<div id="installation" class="section level2">
<h2 class="hasAnchor">
<a href="#installation" class="anchor"></a>Installation</h2>
<p>You can install the <strong>rsparkling</strong> package from CRAN as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">install.packages</span>(<span class="st">"rsparkling"</span>)</code></pre></div>
<p>Then set the Sparkling Water version for rsparkling.:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">options</span>(<span class="dt">rsparkling.sparklingwater.version =</span> <span class="st">"2.1.0"</span>)</code></pre></div>
<p>For Spark <code>2.0.x</code> set <code>rsparkling.sparklingwater.version</code> to <code>2.0.3</code> instead, for Spark <code>1.6.2</code> use <code>1.6.8</code>.</p>
</div>
<div id="using-h2o" class="section level2">
<h2 class="hasAnchor">
<a href="#using-h2o" class="anchor"></a>Using H2O</h2>
<p>Now let’s walk through a simple example to demonstrate the use of H2O’s machine learning algorithms within R. We’ll use <a href="http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/glm.html">h2o.glm</a> to fit a linear regression model. Using the built-in <code>mtcars</code> dataset, we’ll try to predict a car’s fuel consumption (<code>mpg</code>) based on its weight (<code>wt</code>), and the number of cylinders the engine contains (<code>cyl</code>).</p>
<p>First, we will initialize a local Spark connection, and copy the <code>mtcars</code> dataset into Spark.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rsparkling)
<span class="kw">library</span>(sparklyr)
<span class="kw">library</span>(h2o)
<span class="kw">library</span>(dplyr)

sc &lt;-<span class="st"> </span><span class="kw"><a href="../reference/spark-connections.html">spark_connect</a></span>(<span class="st">"local"</span>, <span class="dt">version =</span> <span class="st">"2.1.0"</span>)

mtcars_tbl &lt;-<span class="st"> </span><span class="kw">copy_to</span>(sc, mtcars, <span class="st">"mtcars"</span>)</code></pre></div>
<p>Now, let’s perform some simple transformations – we’ll</p>
<ol style="list-style-type: decimal">
<li>Remove all cars with horsepower less than 100,</li>
<li>Produce a column encoding whether a car has 8 cylinders or not,</li>
<li>Partition the data into separate training and test data sets,</li>
<li>Fit a model to our training data set,</li>
<li>Evaluate our predictive performance on our test dataset.</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># transform our data set, and then partition into 'training', 'test'</span>
partitions &lt;-<span class="st"> </span>mtcars_tbl <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(hp <span class="op">&gt;=</span><span class="st"> </span><span class="dv">100</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">cyl8 =</span> cyl <span class="op">==</span><span class="st"> </span><span class="dv">8</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="../reference/sdf_partition.html">sdf_partition</a></span>(<span class="dt">training =</span> <span class="fl">0.5</span>, <span class="dt">test =</span> <span class="fl">0.5</span>, <span class="dt">seed =</span> <span class="dv">1099</span>)</code></pre></div>
<p>Now, we convert our training and test sets into H2O Frames using rsparkling conversion functions. We have already split the data into training and test frames using dplyr.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">training &lt;-<span class="st"> </span><span class="kw">as_h2o_frame</span>(sc, partitions<span class="op">$</span>training, <span class="dt">strict_version_check =</span> <span class="ot">FALSE</span>)</code></pre></div>
<pre><code>## Warning in h2o.clusterInfo(): 
## Your H2O cluster version is too old (7 months and 10 days)!
## Please download and install the latest version from http://h2o.ai/download/</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">test &lt;-<span class="st"> </span><span class="kw">as_h2o_frame</span>(sc, partitions<span class="op">$</span>test, <span class="dt">strict_version_check =</span> <span class="ot">FALSE</span>)</code></pre></div>
<pre><code>## Warning in h2o.clusterInfo(): 
## Your H2O cluster version is too old (7 months and 10 days)!
## Please download and install the latest version from http://h2o.ai/download/</code></pre>
<p>Alternatively, we can use the <code>h2o.splitFrame()</code> function instead of <code><a href="../reference/sdf_partition.html">sdf_partition()</a></code> to partition the data within H2O instead of Spark (e.g. <code>partitions &lt;- h2o.splitFrame(as_h2o_frame(mtcars_tbl), 0.5)</code>)</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># fit a linear model to the training dataset</span>
glm_model &lt;-<span class="st"> </span><span class="kw">h2o.glm</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="st">"wt"</span>, <span class="st">"cyl"</span>), 
                     <span class="dt">y =</span> <span class="st">"mpg"</span>, 
                     <span class="dt">training_frame =</span> training,
                     <span class="dt">lambda_search =</span> <span class="ot">TRUE</span>)</code></pre></div>
<p>For linear regression models produced by H2O, we can use either <code>print()</code> or <code>summary()</code> to learn a bit more about the quality of our fit. The <code>summary()</code> method returns some extra information about scoring history and variable importance.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">glm_model</code></pre></div>
<pre><code>## Model Details:
## ==============
## 
## H2ORegressionModel: glm
## Model ID:  GLM_model_R_1505092734653_1 
## GLM Model: summary
##     family     link                               regularization
## 1 gaussian identity Elastic Net (alpha = 0.5, lambda = 0.05468 )
##                                                                 lambda_search
## 1 nlambda = 100, lambda.max = 5.4682, lambda.min = 0.05468, lambda.1se = -1.0
##   number_of_predictors_total number_of_active_predictors
## 1                          2                           2
##   number_of_iterations                                training_frame
## 1                    0 frame_rdd_32_805215c1fd8eb23cdbc43d9dc3e54014
## 
## Coefficients: glm coefficients
##       names coefficients standardized_coefficients
## 1 Intercept    32.997281                 16.625000
## 2       cyl    -0.906688                 -1.349195
## 3        wt    -2.712562                 -2.282649
## 
## H2ORegressionMetrics: glm
## ** Reported on training data. **
## 
## MSE:  2.03293
## RMSE:  1.425808
## MAE:  1.306314
## RMSLE:  0.08238032
## Mean Residual Deviance :  2.03293
## R^2 :  0.8265696
## Null Deviance :93.775
## Null D.o.F. :7
## Residual Deviance :16.26344
## Residual D.o.F. :5
## AIC :36.37884</code></pre>
<p>The output suggests that our model is a fairly good fit, and that both a cars weight, as well as the number of cylinders in its engine, will be powerful predictors of its average fuel consumption. (The model suggests that, on average, heavier cars consume more fuel.)</p>
<p>Let’s use our H2O model fit to predict the average fuel consumption on our test data set, and compare the predicted response with the true measured fuel consumption. We’ll build a simple ggplot2 plot that will allow us to inspect the quality of our predictions.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggplot2)

<span class="co"># compute predicted values on our test dataset</span>
pred &lt;-<span class="st"> </span><span class="kw">h2o.predict</span>(glm_model, <span class="dt">newdata =</span> test)
<span class="co"># convert from H2O Frame to Spark DataFrame</span>
predicted &lt;-<span class="st"> </span><span class="kw">as_spark_dataframe</span>(sc, pred, <span class="dt">strict_version_check =</span> <span class="ot">FALSE</span>)

<span class="co"># extract the true 'mpg' values from our test dataset</span>
actual &lt;-<span class="st"> </span>partitions<span class="op">$</span>test <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(mpg) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">collect</span>() <span class="op">%&gt;%</span>
<span class="st">  `</span><span class="dt">[[</span><span class="st">`</span>(<span class="st">"mpg"</span>)

<span class="co"># produce a data.frame housing our predicted + actual 'mpg' values</span>
data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
  <span class="dt">predicted =</span> predicted,
  <span class="dt">actual    =</span> actual
)
<span class="co"># a bug in data.frame does not set colnames properly; reset here </span>
<span class="kw">names</span>(data) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">"predicted"</span>, <span class="st">"actual"</span>)

<span class="co"># plot predicted vs. actual values</span>
<span class="kw">ggplot</span>(data, <span class="kw">aes</span>(<span class="dt">x =</span> actual, <span class="dt">y =</span> predicted)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">lty =</span> <span class="st">"dashed"</span>, <span class="dt">col =</span> <span class="st">"red"</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">plot.title =</span> <span class="kw">element_text</span>(<span class="dt">hjust =</span> <span class="fl">0.5</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_fixed</span>(<span class="dt">ratio =</span> <span class="dv">1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">x =</span> <span class="st">"Actual Fuel Consumption"</span>,
    <span class="dt">y =</span> <span class="st">"Predicted Fuel Consumption"</span>,
    <span class="dt">title =</span> <span class="st">"Predicted vs. Actual Fuel Consumption"</span>
  )</code></pre></div>
<p><img src="guides-h2o_files/figure-html/unnamed-chunk-8-1.png" width="672"></p>
<p>Although simple, our model appears to do a fairly good job of predicting a car’s average fuel consumption.</p>
<p>As you can see, we can easily and effectively combine dplyr data transformation pipelines with the machine learning algorithms provided by H2O’s Sparkling Water.</p>
</div>
<div id="algorithms" class="section level2">
<h2 class="hasAnchor">
<a href="#algorithms" class="anchor"></a>Algorithms</h2>
<p>Once the <code>H2OContext</code> is made available to Spark (as demonstrated below), all of the functions in the standard h2o R interface can be used with H2O Frames (converted from Spark DataFrames). Here is a table of the available algorithms:</p>
<table class="table">
<thead><tr class="header">
<th>Function</th>
<th>Description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><a href="http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/glm.html"><code>h2o.glm</code></a></td>
<td>Generalized Linear Model</td>
</tr>
<tr class="even">
<td><a href="http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/deep-learning.html"><code>h2o.deeplearning</code></a></td>
<td>Multilayer Perceptron</td>
</tr>
<tr class="odd">
<td><a href="http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/drf.html"><code>h2o.randomForest</code></a></td>
<td>Random Forest</td>
</tr>
<tr class="even">
<td><a href="http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/gbm.html"><code>h2o.gbm</code></a></td>
<td>Gradient Boosting Machine</td>
</tr>
<tr class="odd">
<td><a href="http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/naive-bayes.html"><code>h2o.naiveBayes</code></a></td>
<td>Naive-Bayes</td>
</tr>
<tr class="even">
<td><a href="http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/pca.html"><code>h2o.prcomp</code></a></td>
<td>Principal Components Analysis</td>
</tr>
<tr class="odd">
<td><a href="https://www.rdocumentation.org/packages/h2o/versions/3.8.3.3/topics/h2o.svd"><code>h2o.svd</code></a></td>
<td>Singular Value Decomposition</td>
</tr>
<tr class="even">
<td><a href="http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/glrm.html"><code>h2o.glrm</code></a></td>
<td>Generalized Low Rank Model</td>
</tr>
<tr class="odd">
<td><a href="http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/k-means.html"><code>h2o.kmeans</code></a></td>
<td>K-Means Clustering</td>
</tr>
<tr class="even">
<td><a href="https://www.rdocumentation.org/packages/h2o/versions/3.8.3.3/topics/h2o.anomaly"><code>h2o.anomaly</code></a></td>
<td>Anomaly Detection via Deep Learning Autoencoder</td>
</tr>
</tbody>
</table>
<p>Additionally, the <a href="https://github.com/h2oai/h2o-3/tree/master/h2o-r/ensemble">h2oEnsemble</a> R package can be used to generate Super Learner ensembles of H2O algorithms:</p>
<table class="table">
<thead><tr class="header">
<th>Function</th>
<th>Description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><a href="http://learn.h2o.ai/content/tutorials/ensembles-stacking/"><code>h2o.ensemble</code></a></td>
<td>Super Learner / Stacking</td>
</tr>
<tr class="even">
<td><a href="https://github.com/h2oai/h2o-3/blob/master/h2o-r/ensemble/demos/h2o_stack_documentation_example.R"><code>h2o.stack</code></a></td>
<td>Super Learner / Stacking</td>
</tr>
</tbody>
</table>
</div>
<div id="transformers" class="section level2">
<h2 class="hasAnchor">
<a href="#transformers" class="anchor"></a>Transformers</h2>
<p>A model is often fit not on a dataset as-is, but instead on some transformation of that dataset. Spark provides <a href="http://spark.apache.org/docs/latest/ml-features.html">feature transformers</a>, facilitating many common transformations of data within a Spark DataFrame, and sparklyr exposes these within the <code>ft_*</code> family of functions. Transformers can be used on Spark DataFrames, and the final training set can be sent to the H2O cluster for machine learning.</p>
<table class="table">
<colgroup>
<col width="38%">
<col width="61%">
</colgroup>
<thead><tr class="header">
<th>
Function
</th>
<th>
Description
</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>
<a href="reference/sparklyr/latest/ft_binarizer.html"><code>ft_binarizer</code></a>
</td>
<td>
Threshold numerical features to binary (0/1) feature
</td>
</tr>
<tr class="even">
<td>
<a href="reference/sparklyr/latest/ft_bucketizer.html"><code>ft_bucketizer</code></a>
</td>
<td>
Bucketizer transforms a column of continuous features to a column of feature buckets
</td>
</tr>
<tr class="odd">
<td>
<a href="reference/sparklyr/latest/ft_discrete_cosine_transform.html"><code>ft_discrete_cosine_transform</code></a>
</td>
<td>
Transforms a length NN real-valued sequence in the time domain into another length NN real-valued sequence in the frequency domain
</td>
</tr>
<tr class="even">
<td>
<a href="reference/sparklyr/latest/ft_elementwise_product.html"><code>ft_elementwise_product</code></a>
</td>
<td>
Multiplies each input vector by a provided weight vector, using element-wise multiplication.
</td>
</tr>
<tr class="odd">
<td>
<a href="reference/sparklyr/latest/ft_index_to_string.html"><code>ft_index_to_string</code></a>
</td>
<td>
Maps a column of label indices back to a column containing the original labels as strings
</td>
</tr>
<tr class="even">
<td>
<a href="reference/sparklyr/latest/ft_quantile_discretizer.html"><code>ft_quantile_discretizer</code></a>
</td>
<td>
Takes a column with continuous features and outputs a column with binned categorical features
</td>
</tr>
<tr class="odd">
<td>
<a href="reference/sparklyr/latest/ft_sql_transformer.html"><code>ft_sql_transformer</code></a>
</td>
<td>
Implements the transformations which are defined by a SQL statement
</td>
</tr>
<tr class="even">
<td>
<a href="reference/sparklyr/latest/ft_string_indexer.html"><code>ft_string_indexer</code></a>
</td>
<td>
Encodes a string column of labels to a column of label indices
</td>
</tr>
<tr class="odd">
<td>
<a href="reference/sparklyr/latest/ft_vector_assembler.html"><code>ft_vector_assembler</code></a>
</td>
<td>
Combines a given list of columns into a single vector column
</td>
</tr>
</tbody>
</table>
</div>
<div id="examples" class="section level2">
<h2 class="hasAnchor">
<a href="#examples" class="anchor"></a>Examples</h2>
<p>We will use the <code>iris</code> data set to examine a handful of learning algorithms and transformers. The iris data set measures attributes for 150 flowers in 3 different species of iris.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">iris_tbl &lt;-<span class="st"> </span><span class="kw">copy_to</span>(sc, iris, <span class="st">"iris"</span>, <span class="dt">overwrite =</span> <span class="ot">TRUE</span>)
iris_tbl</code></pre></div>
<pre><code>## # Source:   table&lt;iris&gt; [?? x 5]
## # Database: spark_connection
##    Sepal_Length Sepal_Width Petal_Length Petal_Width Species
##           &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;   &lt;chr&gt;
##  1          5.1         3.5          1.4         0.2  setosa
##  2          4.9         3.0          1.4         0.2  setosa
##  3          4.7         3.2          1.3         0.2  setosa
##  4          4.6         3.1          1.5         0.2  setosa
##  5          5.0         3.6          1.4         0.2  setosa
##  6          5.4         3.9          1.7         0.4  setosa
##  7          4.6         3.4          1.4         0.3  setosa
##  8          5.0         3.4          1.5         0.2  setosa
##  9          4.4         2.9          1.4         0.2  setosa
## 10          4.9         3.1          1.5         0.1  setosa
## # ... with more rows</code></pre>
<p>Convert to an H2O Frame:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">iris_hf &lt;-<span class="st"> </span><span class="kw">as_h2o_frame</span>(sc, iris_tbl, <span class="dt">strict_version_check =</span> <span class="ot">FALSE</span>)</code></pre></div>
<div id="k-means-clustering" class="section level3">
<h3 class="hasAnchor">
<a href="#k-means-clustering" class="anchor"></a>K-Means Clustering</h3>
<p>Use H2O’s <a href="http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/k-means.html">K-means clustering</a> to partition a dataset into groups. K-means clustering partitions points into <code>k</code> groups, such that the sum of squares from points to the assigned cluster centers is minimized.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">kmeans_model &lt;-<span class="st"> </span><span class="kw">h2o.kmeans</span>(<span class="dt">training_frame =</span> iris_hf, 
                           <span class="dt">x =</span> <span class="dv">3</span><span class="op">:</span><span class="dv">4</span>,
                           <span class="dt">k =</span> <span class="dv">3</span>,
                           <span class="dt">seed =</span> <span class="dv">1</span>)</code></pre></div>
<p>To look at particular metrics of the K-means model, we can use <code>h2o.centroid_stats()</code> and <code>h2o.centers()</code> or simply print out all the model metrics using <code>print(kmeans_model)</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># print the cluster centers</span>
<span class="kw">h2o.centers</span>(kmeans_model)</code></pre></div>
<pre><code>##   petal_length petal_width
## 1     1.462000     0.24600
## 2     5.566667     2.05625
## 3     4.296154     1.32500</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># print the centroid statistics</span>
<span class="kw">h2o.centroid_stats</span>(kmeans_model)</code></pre></div>
<pre><code>## Centroid Statistics: 
##   centroid     size within_cluster_sum_of_squares
## 1        1 50.00000                       1.41087
## 2        2 48.00000                       9.29317
## 3        3 52.00000                       7.20274</code></pre>
</div>
<div id="pca" class="section level3">
<h3 class="hasAnchor">
<a href="#pca" class="anchor"></a>PCA</h3>
<p>Use H2O’s <a href="http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/pca.html">Principal Components Analysis (PCA)</a> to perform dimensionality reduction. PCA is a statistical method to find a rotation such that the first coordinate has the largest variance possible, and each succeeding coordinate in turn has the largest variance possible.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pca_model &lt;-<span class="st"> </span><span class="kw">h2o.prcomp</span>(<span class="dt">training_frame =</span> iris_hf,
                        <span class="dt">x =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">4</span>,
                        <span class="dt">k =</span> <span class="dv">4</span>,
                        <span class="dt">seed =</span> <span class="dv">1</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pca_model</code></pre></div>
<pre><code>## Model Details:
## ==============
## 
## H2ODimReductionModel: pca
## Model ID:  PCA_model_R_1505092734653_3 
## Importance of components: 
##                             pc1      pc2      pc3      pc4
## Standard deviation     7.861342 1.455041 0.283531 0.154411
## Proportion of Variance 0.965303 0.033069 0.001256 0.000372
## Cumulative Proportion  0.965303 0.998372 0.999628 1.000000
## 
## 
## H2ODimReductionMetrics: pca
## 
## No model metrics available for PCA</code></pre>
</div>
<div id="random-forest" class="section level3">
<h3 class="hasAnchor">
<a href="#random-forest" class="anchor"></a>Random Forest</h3>
<p>Use H2O’s <a href="http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/drf.html">Random Forest</a> to perform regression or classification on a dataset. We will continue to use the iris dataset as an example for this problem.</p>
<p>As usual, we define the response and predictor variables using the <code>x</code> and <code>y</code> arguments. Since we’d like to do a classification, we need to ensure that the response column is encoded as a factor (enum) column.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">y &lt;-<span class="st"> "Species"</span>
x &lt;-<span class="st"> </span><span class="kw">setdiff</span>(<span class="kw">names</span>(iris_hf), y)
iris_hf[,y] &lt;-<span class="st"> </span><span class="kw">as.factor</span>(iris_hf[,y])</code></pre></div>
<p>We can split the <code>iris_hf</code> H2O Frame into a train and test set (the split defaults to 75/25 train/test).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">splits &lt;-<span class="st"> </span><span class="kw">h2o.splitFrame</span>(iris_hf, <span class="dt">seed =</span> <span class="dv">1</span>)</code></pre></div>
<p>Then we can train a Random Forest model:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rf_model &lt;-<span class="st"> </span><span class="kw">h2o.randomForest</span>(<span class="dt">x =</span> x, 
                             <span class="dt">y =</span> y,
                             <span class="dt">training_frame =</span> splits[[<span class="dv">1</span>]],
                             <span class="dt">validation_frame =</span> splits[[<span class="dv">2</span>]],
                             <span class="dt">nbins =</span> <span class="dv">32</span>,
                             <span class="dt">max_depth =</span> <span class="dv">5</span>,
                             <span class="dt">ntrees =</span> <span class="dv">20</span>,
                             <span class="dt">seed =</span> <span class="dv">1</span>)</code></pre></div>
<p>Since we passed a validation frame, the validation metrics will be calculated. We can retrieve individual metrics using functions such as <code>h2o.mse(rf_model, valid = TRUE)</code>. The confusion matrix can be printed using the following:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">h2o.confusionMatrix</span>(rf_model, <span class="dt">valid =</span> <span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## Confusion Matrix: vertical: actual; across: predicted
##            setosa versicolor virginica  Error     Rate
## setosa          7          0         0 0.0000 =  0 / 7
## versicolor      0         13         0 0.0000 = 0 / 13
## virginica       0          1        10 0.0909 = 1 / 11
## Totals          7         14        10 0.0323 = 1 / 31</code></pre>
<p>To view the variable importance computed from an H2O model, you can use either the <code>h2o.varimp()</code> or <code>h2o.varimp_plot()</code> functions:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">h2o.varimp_plot</span>(rf_model)</code></pre></div>
<p><img src="guides-h2o_files/figure-html/unnamed-chunk-20-1.png" width="672"></p>
</div>
<div id="gradient-boosting-machine" class="section level3">
<h3 class="hasAnchor">
<a href="#gradient-boosting-machine" class="anchor"></a>Gradient Boosting Machine</h3>
<p>The <a href="http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/gbm.html">Gradient Boosting Machine (GBM)</a> is one of H2O’s most popular algorithms, as it works well on many types of data. We will continue to use the iris dataset as an example for this problem.</p>
<p>Using the same dataset and <code>x</code> and <code>y</code> from above, we can train a GBM:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">gbm_model &lt;-<span class="st"> </span><span class="kw">h2o.gbm</span>(<span class="dt">x =</span> x, 
                     <span class="dt">y =</span> y,
                     <span class="dt">training_frame =</span> splits[[<span class="dv">1</span>]],
                     <span class="dt">validation_frame =</span> splits[[<span class="dv">2</span>]],                     
                     <span class="dt">ntrees =</span> <span class="dv">20</span>,
                     <span class="dt">max_depth =</span> <span class="dv">3</span>,
                     <span class="dt">learn_rate =</span> <span class="fl">0.01</span>,
                     <span class="dt">col_sample_rate =</span> <span class="fl">0.7</span>,
                     <span class="dt">seed =</span> <span class="dv">1</span>)</code></pre></div>
<p>Since this is a multi-class problem, we may be interested in inspecting the confusion matrix on a hold-out set. Since we passed along a <code>validatin_frame</code> at train time, the validation metrics are already computed and we just need to retreive them from the model object.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">h2o.confusionMatrix</span>(gbm_model, <span class="dt">valid =</span> <span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## Confusion Matrix: vertical: actual; across: predicted
##            setosa versicolor virginica  Error     Rate
## setosa          7          0         0 0.0000 =  0 / 7
## versicolor      0         13         0 0.0000 = 0 / 13
## virginica       0          1        10 0.0909 = 1 / 11
## Totals          7         14        10 0.0323 = 1 / 31</code></pre>
</div>
<div id="deep-learning" class="section level3">
<h3 class="hasAnchor">
<a href="#deep-learning" class="anchor"></a>Deep Learning</h3>
<p>Use H2O’s <a href="http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/deep-learning.html">Deep Learning</a> to perform regression or classification on a dataset, extact non-linear features generated by the deep neural network, and/or detect anomalies using a deep learning model with auto-encoding.</p>
<p>In this example, we will use the <code>prostate</code> dataset available within the h2o package:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">path &lt;-<span class="st"> </span><span class="kw">system.file</span>(<span class="st">"extdata"</span>, <span class="st">"prostate.csv"</span>, <span class="dt">package =</span> <span class="st">"h2o"</span>)
prostate_df &lt;-<span class="st"> </span><span class="kw"><a href="../reference/spark_read_csv.html">spark_read_csv</a></span>(sc, <span class="st">"prostate"</span>, path)
<span class="kw">head</span>(prostate_df)</code></pre></div>
<pre><code>## # Source:   lazy query [?? x 9]
## # Database: spark_connection
##      ID CAPSULE   AGE  RACE DPROS DCAPS   PSA   VOL GLEASON
##   &lt;int&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;int&gt;
## 1     1       0    65     1     2     1   1.4   0.0       6
## 2     2       0    72     1     3     2   6.7   0.0       7
## 3     3       0    70     1     1     2   4.9   0.0       6
## 4     4       0    76     2     2     1  51.2  20.0       7
## 5     5       0    69     1     1     1  12.3  55.9       6
## 6     6       1    71     1     3     2   3.3   0.0       8</code></pre>
<p>Once we’ve done whatever data manipulation is required to run our model we’ll get a reference to it as an h2o frame then split it into training and test sets using the <code>h2o.splitFrame</code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">prostate_hf &lt;-<span class="st"> </span><span class="kw">as_h2o_frame</span>(sc, prostate_df, <span class="dt">strict_version_check =</span> <span class="ot">FALSE</span>)
splits &lt;-<span class="st"> </span><span class="kw">h2o.splitFrame</span>(prostate_hf, <span class="dt">seed =</span> <span class="dv">1</span>)</code></pre></div>
<p>Next we define the response and predictor columns.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">y &lt;-<span class="st"> "VOL"</span>
<span class="co">#remove response and ID cols</span>
x &lt;-<span class="st"> </span><span class="kw">setdiff</span>(<span class="kw">names</span>(prostate_hf), <span class="kw">c</span>(<span class="st">"ID"</span>, y))</code></pre></div>
<p>Now we can train a deep neural net.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dl_fit &lt;-<span class="st"> </span><span class="kw">h2o.deeplearning</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y,
                           <span class="dt">training_frame =</span> splits[[<span class="dv">1</span>]],
                           <span class="dt">epochs =</span> <span class="dv">15</span>,
                           <span class="dt">activation =</span> <span class="st">"Rectifier"</span>,
                           <span class="dt">hidden =</span> <span class="kw">c</span>(<span class="dv">10</span>, <span class="dv">5</span>, <span class="dv">10</span>),
                           <span class="dt">input_dropout_ratio =</span> <span class="fl">0.7</span>)</code></pre></div>
<p>Evaluate performance on a test set:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">h2o.performance</span>(dl_fit, <span class="dt">newdata =</span> splits[[<span class="dv">2</span>]])</code></pre></div>
<pre><code>## H2ORegressionMetrics: deeplearning
## 
## MSE:  251.2473
## RMSE:  15.85078
## MAE:  13.024
## RMSLE:  NaN
## Mean Residual Deviance :  251.2473</code></pre>
<p>Note that the above metrics are not reproducible when H2O’s Deep Learning is run on multiple cores, however, the metrics should be fairly stable across repeat runs.</p>
</div>
<div id="grid-search" class="section level3">
<h3 class="hasAnchor">
<a href="#grid-search" class="anchor"></a>Grid Search</h3>
<p>H2O’s grid search capabilities currently supports traditional (Cartesian) grid search and random grid search. Grid search in R provides the following capabilities:</p>
<ul>
<li>
<code>H2OGrid</code> class: Represents the results of the grid search</li>
<li>
<code>h2o.getGrid(&lt;grid_id&gt;, sort_by, decreasing)</code>: Display the specified grid</li>
<li>
<code>h2o.grid</code>: Start a new grid search parameterized by
<ul>
<li>model builder name (e.g., <code>algorithm = "gbm"</code>)</li>
<li>model parameters (e.g., <code>ntrees = 100</code>)</li>
<li>
<code>hyper_parameters</code>: attribute for passing a list of hyper parameters (e.g., <code>list(ntrees=c(1,100), learn_rate=c(0.1,0.001))</code>)</li>
<li>
<code>search_criteria</code>: optional attribute for specifying more a advanced search strategy</li>
</ul>
</li>
</ul>
<div id="cartesian-grid-search" class="section level4">
<h4 class="hasAnchor">
<a href="#cartesian-grid-search" class="anchor"></a>Cartesian Grid Search</h4>
<p>By default, <code>h2o.grid()</code> will train a Cartesian grid search – meaning, all possible models in the specified grid. In this example, we will re-use the prostate data as an example dataset for a regression problem.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">splits &lt;-<span class="st"> </span><span class="kw">h2o.splitFrame</span>(prostate_hf, <span class="dt">seed =</span> <span class="dv">1</span>)

y &lt;-<span class="st"> "VOL"</span>
<span class="co">#remove response and ID cols</span>
x &lt;-<span class="st"> </span><span class="kw">setdiff</span>(<span class="kw">names</span>(prostate_hf), <span class="kw">c</span>(<span class="st">"ID"</span>, y))</code></pre></div>
<p>After prepping the data, we define a grid and execute the grid search.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># GBM hyperparamters</span>
gbm_params1 &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">learn_rate =</span> <span class="kw">c</span>(<span class="fl">0.01</span>, <span class="fl">0.1</span>),
                    <span class="dt">max_depth =</span> <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">9</span>),
                    <span class="dt">sample_rate =</span> <span class="kw">c</span>(<span class="fl">0.8</span>, <span class="fl">1.0</span>),
                    <span class="dt">col_sample_rate =</span> <span class="kw">c</span>(<span class="fl">0.2</span>, <span class="fl">0.5</span>, <span class="fl">1.0</span>))

<span class="co"># Train and validate a grid of GBMs</span>
gbm_grid1 &lt;-<span class="st"> </span><span class="kw">h2o.grid</span>(<span class="st">"gbm"</span>, <span class="dt">x =</span> x, <span class="dt">y =</span> y,
                      <span class="dt">grid_id =</span> <span class="st">"gbm_grid1"</span>,
                      <span class="dt">training_frame =</span> splits[[<span class="dv">1</span>]],
                      <span class="dt">validation_frame =</span> splits[[<span class="dv">1</span>]],
                      <span class="dt">ntrees =</span> <span class="dv">100</span>,
                      <span class="dt">seed =</span> <span class="dv">1</span>,
                      <span class="dt">hyper_params =</span> gbm_params1)

<span class="co"># Get the grid results, sorted by validation MSE</span>
gbm_gridperf1 &lt;-<span class="st"> </span><span class="kw">h2o.getGrid</span>(<span class="dt">grid_id =</span> <span class="st">"gbm_grid1"</span>, 
                             <span class="dt">sort_by =</span> <span class="st">"mse"</span>, 
                             <span class="dt">decreasing =</span> <span class="ot">FALSE</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">gbm_gridperf1</code></pre></div>
<pre><code>## H2O Grid Details
## ================
## 
## Grid ID: gbm_grid1 
## Used hyper parameters: 
##   -  col_sample_rate 
##   -  learn_rate 
##   -  max_depth 
##   -  sample_rate 
## Number of models: 36 
## Number of failed models: 0 
## 
## Hyper-Parameter Search Summary: ordered by increasing mse
##   col_sample_rate learn_rate max_depth sample_rate          model_ids
## 1             1.0        0.1         9         1.0 gbm_grid1_model_35
## 2             0.5        0.1         9         1.0 gbm_grid1_model_34
## 3             1.0        0.1         9         0.8 gbm_grid1_model_17
## 4             0.5        0.1         9         0.8 gbm_grid1_model_16
## 5             1.0        0.1         5         0.8 gbm_grid1_model_11
##                  mse
## 1  88.10947523138782
## 2  102.3118989994892
## 3 102.78632321923726
## 4  126.4217260351778
## 5  149.6066650109763
## 
## ---
##    col_sample_rate learn_rate max_depth sample_rate          model_ids
## 31             0.5       0.01         3         0.8  gbm_grid1_model_1
## 32             0.2       0.01         5         1.0 gbm_grid1_model_24
## 33             0.5       0.01         3         1.0 gbm_grid1_model_19
## 34             0.2       0.01         5         0.8  gbm_grid1_model_6
## 35             0.2       0.01         3         1.0 gbm_grid1_model_18
## 36             0.2       0.01         3         0.8  gbm_grid1_model_0
##                   mse
## 31  324.8117304723162
## 32 325.10992525687294
## 33 325.27898443785045
## 34 329.36983845305735
## 35 338.54411936919456
## 36  339.7744828617712</code></pre>
</div>
<div id="random-grid-search" class="section level4">
<h4 class="hasAnchor">
<a href="#random-grid-search" class="anchor"></a>Random Grid Search</h4>
<p>H2O’s Random Grid Search samples from the given parameter space until a set of constraints is met. The user can specify the total number of desired models using (e.g. <code>max_models = 40</code>), the amount of time (e.g. <code>max_runtime_secs = 1000</code>), or tell the grid to stop after performance stops improving by a specified amount. Random Grid Search is a practical way to arrive at a good model without too much effort.</p>
<p>The example below is set to run fairly quickly – increase <code>max_runtime_secs</code> or <code>max_models</code> to cover more of the hyperparameter space in your grid search. Also, you can expand the hyperparameter space of each of the algorithms by modifying the definition of <code>hyper_param</code> below.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># GBM hyperparamters</span>
gbm_params2 &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">learn_rate =</span> <span class="kw">seq</span>(<span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="fl">0.01</span>),
                    <span class="dt">max_depth =</span> <span class="kw">seq</span>(<span class="dv">2</span>, <span class="dv">10</span>, <span class="dv">1</span>),
                    <span class="dt">sample_rate =</span> <span class="kw">seq</span>(<span class="fl">0.5</span>, <span class="fl">1.0</span>, <span class="fl">0.1</span>),
                    <span class="dt">col_sample_rate =</span> <span class="kw">seq</span>(<span class="fl">0.1</span>, <span class="fl">1.0</span>, <span class="fl">0.1</span>))
search_criteria2 &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">strategy =</span> <span class="st">"RandomDiscrete"</span>, 
                         <span class="dt">max_models =</span> <span class="dv">50</span>)

<span class="co"># Train and validate a grid of GBMs</span>
gbm_grid2 &lt;-<span class="st"> </span><span class="kw">h2o.grid</span>(<span class="st">"gbm"</span>, <span class="dt">x =</span> x, <span class="dt">y =</span> y,
                      <span class="dt">grid_id =</span> <span class="st">"gbm_grid2"</span>,
                      <span class="dt">training_frame =</span> splits[[<span class="dv">1</span>]],
                      <span class="dt">validation_frame =</span> splits[[<span class="dv">2</span>]],
                      <span class="dt">ntrees =</span> <span class="dv">100</span>,
                      <span class="dt">seed =</span> <span class="dv">1</span>,
                      <span class="dt">hyper_params =</span> gbm_params2,
                      <span class="dt">search_criteria =</span> search_criteria2)

<span class="co"># Get the grid results, sorted by validation MSE</span>
gbm_gridperf2 &lt;-<span class="st"> </span><span class="kw">h2o.getGrid</span>(<span class="dt">grid_id =</span> <span class="st">"gbm_grid2"</span>, 
                             <span class="dt">sort_by =</span> <span class="st">"mse"</span>, 
                             <span class="dt">decreasing =</span> <span class="ot">FALSE</span>)</code></pre></div>
<p>To get the best model, as measured by validation MSE, we simply grab the first row of the <code>gbm_gridperf2@summary_table</code> object, since this table is already sorted such that the lowest MSE model is on top.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">gbm_gridperf2<span class="op">@</span>summary_table[<span class="dv">1</span>,]</code></pre></div>
<pre><code>## Hyper-Parameter Search Summary: ordered by increasing mse
##   col_sample_rate learn_rate max_depth sample_rate         model_ids
## 1             0.2       0.01         4         0.7 gbm_grid2_model_4
##                 mse
## 1 248.9520189471835</code></pre>
<p>In the examples above, we generated two different grids, specified by <code>grid_id</code>. The first grid was called <code>grid_id = "gbm_grid1"</code> and the second was called <code>grid_id = "gbm_grid2"</code>. However, if we are using the same dataset &amp; algorithm in two grid searches, it probably makes more sense just to add the results of the second grid search to the first. If you want to add models to an existing grid, rather than create a new one, you simply re-use the same <code>grid_id</code>.</p>
</div>
</div>
</div>
<div id="exporting-models" class="section level2">
<h2 class="hasAnchor">
<a href="#exporting-models" class="anchor"></a>Exporting Models</h2>
<p>There are two ways of exporting models from H2O – saving models as a binary file, or saving models as pure Java code.</p>
<div id="binary-models" class="section level4">
<h4 class="hasAnchor">
<a href="#binary-models" class="anchor"></a>Binary Models</h4>
<p>The more traditional method is to save a binary model file to disk using the <code>h2o.saveModel()</code> function. To load the models using <code>h2o.loadModel()</code>, the same version of H2O that generated the models is required. This method is commonly used when H2O is being used in a non-production setting.</p>
<p>A binary model can be saved as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">h2o.saveModel</span>(my_model, <span class="dt">path =</span> <span class="st">"/Users/me/h2omodels"</span>)</code></pre></div>
</div>
<div id="java-pojo-models" class="section level4">
<h4 class="hasAnchor">
<a href="#java-pojo-models" class="anchor"></a>Java (POJO) Models</h4>
<p>One of the most valuable features of H2O is it’s ability to export models as pure Java code, or rather, a “Plain Old Java Object” (POJO). You can learn more about H2O POJO models in this <a href="http://docs.h2o.ai/h2o/latest-stable/h2o-docs/pojo-quick-start.html">POJO quickstart guide</a>. The POJO method is used most commonly when a model is deployed in a production setting. POJO models are ideal for when you need very fast prediction response times, and minimal requirements – the POJO is a standalone Java class with no dependencies on the full H2O stack.</p>
<p>To generate the POJO for your model, use the following command:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">h2o.download_pojo</span>(my_model, <span class="dt">path =</span> <span class="st">"/Users/me/h2omodels"</span>)</code></pre></div>
<p>Finally, disconnect with:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/spark-connections.html">spark_disconnect_all</a></span>()</code></pre></div>
<pre><code>## [1] 1</code></pre>
<p>You can learn more about how to take H2O models to production in the <a href="http://docs.h2o.ai/h2o/latest-stable/h2o-docs/productionizing.html">productionizing H2O models</a> section of the H2O docs.</p>
</div>
</div>
<div id="additional-resources" class="section level2">
<h2 class="hasAnchor">
<a href="#additional-resources" class="anchor"></a>Additional Resources</h2>
<ul>
<li><a href="http://docs.h2o.ai">Main documentation site for Sparkling Water (and all H2O software projects)</a></li>
<li><a href="http://h2o.ai">H2O.ai website</a></li>
</ul>
<p>If you are new to H2O for machine learning, we recommend you start with the <a href="https://github.com/h2oai/h2o-tutorials/blob/master/h2o-open-tour-2016/chicago/intro-to-h2o.R">Intro to H2O Tutorial</a>, followed by the <a href="https://github.com/h2oai/h2o-tutorials/blob/master/h2o-open-tour-2016/chicago/grid-search-model-selection.R">H2O Grid Search &amp; Model Selection Tutorial</a>. There are a number of other H2O R <a href="https://github.com/h2oai/h2o-tutorials">tutorials</a> and <a href="https://github.com/h2oai/h2o-3/tree/master/h2o-r/demos">demos</a> available, as well as the <a href="http://learn.h2o.ai/content/">H2O World 2015 Training Gitbook</a>, and the <a href="http://docs.h2o.ai/h2o/latest-stable/h2o-docs/booklets/RBooklet.pdf">Machine Learning with R and H2O Booklet (pdf)</a>.</p>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#overview">Overview</a></li>
      <li><a href="#installation">Installation</a></li>
      <li><a href="#using-h2o">Using H2O</a></li>
      <li><a href="#algorithms">Algorithms</a></li>
      <li><a href="#transformers">Transformers</a></li>
      <li><a href="#examples">Examples</a></li>
      <li><a href="#exporting-models">Exporting Models</a></li>
      <li><a href="#additional-resources">Additional Resources</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Javier Luraschi, Kevin Ushey, JJ Allaire,  The Apache Software Foundation.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
