<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Manipulating Data with dplyr • sparklyr</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">sparklyr</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">Home</a>
</li>
<li>
  <a href="../articles/gallery.html">Gallery</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Guides
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/guides-dplyr.html">dplyr</a>
    </li>
    <li>
      <a href="../articles/guides-mllib.html">mllib</a>
    </li>
    <li>
      <a href="../articles/guides-distributed-r.html">Distributed R</a>
    </li>
    <li>
      <a href="../articles/guides-extensions.html">Extensions</a>
    </li>
    <li>
      <a href="../articles/guides-caching.html">Caching</a>
    </li>
    <li>
      <a href="../articles/guides-h2o.html">H2O</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Deployment
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/deployment-overview.html">Overview</a>
    </li>
    <li>
      <a href="../articles/deployment-data-lakes.html">Data Lakes</a>
    </li>
    <li>
      <a href="../articles/deployment-cdh.html">Cloudera</a>
    </li>
    <li>
      <a href="../articles/deployment-amazon.html">Amazon</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Reference
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../reference/index.html">Functions</a>
    </li>
    <li>
      <a href="https://github.com/rstudio/cheatsheets/raw/master/source/pdfs/sparklyr-cheatsheet.pdf">Cheatsheet</a>
    </li>
    <li>
      <a href="../articles/reference-media.html">Media</a>
    </li>
    <li>
      <a href="../news/index.html">News</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/rstudio/sparklyr">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>Manipulating Data with dplyr</h1>
            
          </div>

    
    
<div class="contents">
<div id="overview" class="section level2">
<h2 class="hasAnchor">
<a href="#overview" class="anchor"></a>Overview</h2>
<p><a href="https://cran.r-project.org/web/packages/dplyr/index.html"><strong>dplyr</strong></a> is an R package for working with structured data both in and outside of R. dplyr makes data manipulation for R users easy, consistent, and performant. With dplyr as an interface to manipulating Spark DataFrames, you can:</p>
<ul>
<li>Select, filter, and aggregate data</li>
<li>Use window functions (e.g. for sampling)</li>
<li>Perform joins on DataFrames</li>
<li>Collect data from Spark into R</li>
</ul>
<p>Statements in dplyr can be chained together using pipes defined by the <a href="https://cran.r-project.org/web/packages/magrittr/vignettes/magrittr.html">magrittr</a> R package. dplyr also supports <a href="https://cran.r-project.org/web/packages/dplyr/vignettes/nse.html">non-standard evalution</a> of its arguments. For more information on dplyr, see the <a href="https://cran.r-project.org/web/packages/dplyr/vignettes/introduction.html">introduction</a>, a guide for connecting to <a href="https://cran.r-project.org/web/packages/dplyr/vignettes/databases.html">databases</a>, and a variety of <a href="https://cran.r-project.org/web/packages/dplyr/index.html">vignettes</a>.</p>
</div>
<div id="reading-data" class="section level2">
<h2 class="hasAnchor">
<a href="#reading-data" class="anchor"></a>Reading Data</h2>
<p>You can read data into Spark DataFrames using the following functions:</p>
<table class="table">
<colgroup>
<col width="38%">
<col width="61%">
</colgroup>
<thead><tr class="header">
<th>Function</th>
<th>Description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><a href="reference/sparklyr/latest/spark_read_csv.html"><code>spark_read_csv</code></a></td>
<td>Reads a CSV file and provides a data source compatible with dplyr</td>
</tr>
<tr class="even">
<td><a href="reference/sparklyr/latest/spark_read_json.html"><code>spark_read_json</code></a></td>
<td>Reads a JSON file and provides a data source compatible with dplyr</td>
</tr>
<tr class="odd">
<td><a href="reference/sparklyr/latest/spark_read_json.html"><code>spark_read_parquet</code></a></td>
<td>Reads a parquet file and provides a data source compatible with dplyr</td>
</tr>
</tbody>
</table>
<p>Regardless of the format of your data, Spark supports reading data from a variety of different data sources. These include data stored on HDFS (<code>hdfs://</code> protocol), Amazon S3 (<code>s3n://</code> protocol), or local files available to the Spark worker nodes (<code>file://</code> protocol)</p>
<p>Each of these functions returns a reference to a Spark DataFrame which can be used as a dplyr table (<code>tbl</code>).</p>
<div id="flights-data" class="section level3">
<h3 class="hasAnchor">
<a href="#flights-data" class="anchor"></a>Flights Data</h3>
<p>This guide will demonstrate some of the basic data manipulation verbs of dplyr by using data from the <code>nycflights13</code> R package. This package contains data for all 336,776 flights departing New York City in 2013. It also includes useful metadata on airlines, airports, weather, and planes. The data comes from the US <a href="http://www.transtats.bts.gov/DatabaseInfo.asp?DB_ID=120&amp;Link=0">Bureau of Transportation Statistics</a>, and is documented in <code>?nycflights13</code></p>
<p>Connect to the cluster and copy the flights data using the <code>copy_to</code> function. Caveat: The flight data in <code>nycflights13</code> is convenient for dplyr demonstrations because it is small, but in practice large data should rarely be copied directly from R objects.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(sparklyr)
<span class="kw">library</span>(dplyr)
<span class="kw">library</span>(nycflights13)
<span class="kw">library</span>(ggplot2)

sc &lt;-<span class="st"> </span><span class="kw"><a href="../reference/spark-connections.html">spark_connect</a></span>(<span class="dt">master=</span><span class="st">"local"</span>)
flights &lt;-<span class="st"> </span><span class="kw">copy_to</span>(sc, flights, <span class="st">"flights"</span>)
airlines &lt;-<span class="st"> </span><span class="kw">copy_to</span>(sc, airlines, <span class="st">"airlines"</span>)
<span class="kw">src_tbls</span>(sc)</code></pre></div>
<pre><code>## [1] "airlines" "flights"</code></pre>
</div>
</div>
<div id="dplyr-verbs" class="section level2">
<h2 class="hasAnchor">
<a href="#dplyr-verbs" class="anchor"></a>dplyr Verbs</h2>
<p>Verbs are dplyr commands for manipulating data. When connected to a Spark DataFrame, dplyr translates the commands into Spark SQL statements. Remote data sources use exactly the same five verbs as local data sources. Here are the five verbs with their corresponding SQL commands:</p>
<ul>
<li>
<code>select</code> ~ <code>SELECT</code>
</li>
<li>
<code>filter</code> ~ <code>WHERE</code>
</li>
<li>
<code>arrange</code> ~ <code>ORDER</code>
</li>
<li>
<code>summarise</code> ~ <code>aggregators: sum, min, sd, etc.</code>
</li>
<li>
<code>mutate</code> ~ <code>operators: +, *, log, etc.</code>
</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">select</span>(flights, year<span class="op">:</span>day, arr_delay, dep_delay)</code></pre></div>
<pre><code>## # Source:   lazy query [?? x 5]
## # Database: spark_connection
##     year month   day arr_delay dep_delay
##    &lt;int&gt; &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;     &lt;dbl&gt;
##  1  2013     1     1        11         2
##  2  2013     1     1        20         4
##  3  2013     1     1        33         2
##  4  2013     1     1       -18        -1
##  5  2013     1     1       -25        -6
##  6  2013     1     1        12        -4
##  7  2013     1     1        19        -5
##  8  2013     1     1       -14        -3
##  9  2013     1     1        -8        -3
## 10  2013     1     1         8        -2
## # ... with more rows</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">filter</span>(flights, dep_delay <span class="op">&gt;</span><span class="st"> </span><span class="dv">1000</span>)</code></pre></div>
<pre><code>## # Source:   lazy query [?? x 19]
## # Database: spark_connection
##    year month   day dep_time sched_dep_time dep_delay arr_time
##   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;
## 1  2013     1     9      641            900      1301     1242
## 2  2013     1    10     1121           1635      1126     1239
## 3  2013     6    15     1432           1935      1137     1607
## 4  2013     7    22      845           1600      1005     1044
## 5  2013     9    20     1139           1845      1014     1457
## # ... with 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;,
## #   carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;,
## #   air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;,
## #   time_hour &lt;dbl&gt;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">arrange</span>(flights, <span class="kw">desc</span>(dep_delay))</code></pre></div>
<pre><code>## # Source:     table&lt;flights&gt; [?? x 19]
## # Database:   spark_connection
## # Ordered by: desc(dep_delay)
##     year month   day dep_time sched_dep_time dep_delay arr_time
##    &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;
##  1  2013     1     9      641            900      1301     1242
##  2  2013     6    15     1432           1935      1137     1607
##  3  2013     1    10     1121           1635      1126     1239
##  4  2013     9    20     1139           1845      1014     1457
##  5  2013     7    22      845           1600      1005     1044
##  6  2013     4    10     1100           1900       960     1342
##  7  2013     3    17     2321            810       911      135
##  8  2013     6    27      959           1900       899     1236
##  9  2013     7    22     2257            759       898      121
## 10  2013    12     5      756           1700       896     1058
## # ... with more rows, and 12 more variables: sched_arr_time &lt;int&gt;,
## #   arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;,
## #   origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;,
## #   minute &lt;dbl&gt;, time_hour &lt;dbl&gt;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summarise</span>(flights, <span class="dt">mean_dep_delay =</span> <span class="kw">mean</span>(dep_delay))</code></pre></div>
<pre><code>## # Source:   lazy query [?? x 1]
## # Database: spark_connection
##   mean_dep_delay
##            &lt;dbl&gt;
## 1       12.63907</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mutate</span>(flights, <span class="dt">speed =</span> distance <span class="op">/</span><span class="st"> </span>air_time <span class="op">*</span><span class="st"> </span><span class="dv">60</span>)</code></pre></div>
<pre><code>## # Source:   lazy query [?? x 20]
## # Database: spark_connection
##     year month   day dep_time sched_dep_time dep_delay arr_time
##    &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;
##  1  2013     1     1      517            515         2      830
##  2  2013     1     1      533            529         4      850
##  3  2013     1     1      542            540         2      923
##  4  2013     1     1      544            545        -1     1004
##  5  2013     1     1      554            600        -6      812
##  6  2013     1     1      554            558        -4      740
##  7  2013     1     1      555            600        -5      913
##  8  2013     1     1      557            600        -3      709
##  9  2013     1     1      557            600        -3      838
## 10  2013     1     1      558            600        -2      753
## # ... with more rows, and 13 more variables: sched_arr_time &lt;int&gt;,
## #   arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;,
## #   origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;,
## #   minute &lt;dbl&gt;, time_hour &lt;dbl&gt;, speed &lt;dbl&gt;</code></pre>
</div>
<div id="laziness" class="section level2">
<h2 class="hasAnchor">
<a href="#laziness" class="anchor"></a>Laziness</h2>
<p>When working with databases, dplyr tries to be as lazy as possible:</p>
<ul>
<li><p>It never pulls data into R unless you explicitly ask for it.</p></li>
<li><p>It delays doing any work until the last possible moment: it collects together everything you want to do and then sends it to the database in one step.</p></li>
</ul>
<p>For example, take the following code:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">c1 &lt;-<span class="st"> </span><span class="kw">filter</span>(flights, day <span class="op">==</span><span class="st"> </span><span class="dv">17</span>, month <span class="op">==</span><span class="st"> </span><span class="dv">5</span>, carrier <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">'UA'</span>, <span class="st">'WN'</span>, <span class="st">'AA'</span>, <span class="st">'DL'</span>))
c2 &lt;-<span class="st"> </span><span class="kw">select</span>(c1, year, month, day, carrier, dep_delay, air_time, distance)
c3 &lt;-<span class="st"> </span><span class="kw">arrange</span>(c2, year, month, day, carrier)
c4 &lt;-<span class="st"> </span><span class="kw">mutate</span>(c3, <span class="dt">air_time_hours =</span> air_time <span class="op">/</span><span class="st"> </span><span class="dv">60</span>)</code></pre></div>
<p>This sequence of operations never actually touches the database. It’s not until you ask for the data (e.g. by printing <code>c4</code>) that dplyr requests the results from the database.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">c4</code></pre></div>
<pre><code>## # Source:     lazy query [?? x 8]
## # Database:   spark_connection
## # Ordered by: year, month, day, carrier
##     year month   day carrier dep_delay air_time distance air_time_hours
##    &lt;int&gt; &lt;int&gt; &lt;int&gt;   &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;
##  1  2013     5    17      AA        -2      294     2248       4.900000
##  2  2013     5    17      AA        -1      146     1096       2.433333
##  3  2013     5    17      AA        -2      185     1372       3.083333
##  4  2013     5    17      AA        -9      186     1389       3.100000
##  5  2013     5    17      AA         2      147     1096       2.450000
##  6  2013     5    17      AA        -4      114      733       1.900000
##  7  2013     5    17      AA        -7      117      733       1.950000
##  8  2013     5    17      AA        -7      142     1089       2.366667
##  9  2013     5    17      AA        -6      148     1089       2.466667
## 10  2013     5    17      AA        -7      137      944       2.283333
## # ... with more rows</code></pre>
</div>
<div id="piping" class="section level2">
<h2 class="hasAnchor">
<a href="#piping" class="anchor"></a>Piping</h2>
<p>You can use <a href="https://cran.r-project.org/web/packages/magrittr/vignettes/magrittr.html">magrittr</a> pipes to write cleaner syntax. Using the same example from above, you can write a much cleaner version like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">c4 &lt;-<span class="st"> </span>flights <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(month <span class="op">==</span><span class="st"> </span><span class="dv">5</span>, day <span class="op">==</span><span class="st"> </span><span class="dv">17</span>, carrier <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">'UA'</span>, <span class="st">'WN'</span>, <span class="st">'AA'</span>, <span class="st">'DL'</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(carrier, dep_delay, air_time, distance) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">arrange</span>(carrier) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">air_time_hours =</span> air_time <span class="op">/</span><span class="st"> </span><span class="dv">60</span>)</code></pre></div>
</div>
<div id="grouping" class="section level2">
<h2 class="hasAnchor">
<a href="#grouping" class="anchor"></a>Grouping</h2>
<p>The <code>group_by</code> function corresponds to the <code>GROUP BY</code> statement in SQL.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">c4 <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(carrier) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">count =</span> <span class="kw">n</span>(), <span class="dt">mean_dep_delay =</span> <span class="kw">mean</span>(dep_delay))</code></pre></div>
<pre><code>## # Source:   lazy query [?? x 3]
## # Database: spark_connection
##   carrier count mean_dep_delay
##     &lt;chr&gt; &lt;dbl&gt;          &lt;dbl&gt;
## 1      AA    94       1.468085
## 2      DL   136       6.235294
## 3      UA   172       9.633721
## 4      WN    34       7.970588</code></pre>
</div>
<div id="collecting-to-r" class="section level2">
<h2 class="hasAnchor">
<a href="#collecting-to-r" class="anchor"></a>Collecting to R</h2>
<p>You can copy data from Spark into R’s memory by using <code>collect()</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">carrierhours &lt;-<span class="st"> </span><span class="kw">collect</span>(c4)</code></pre></div>
<p><code>collect()</code> executes the Spark query and returns the results to R for further analysis and visualization.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Test the significance of pairwise differences and plot the results</span>
<span class="kw">with</span>(carrierhours, <span class="kw">pairwise.t.test</span>(air_time, carrier))</code></pre></div>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  air_time and carrier 
## 
##    AA      DL      UA     
## DL 0.25057 -       -      
## UA 0.07957 0.00044 -      
## WN 0.07957 0.23488 0.00041
## 
## P value adjustment method: holm</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(carrierhours, <span class="kw">aes</span>(carrier, air_time_hours)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_boxplot</span>()</code></pre></div>
<p><img src="guides-dplyr_files/figure-html/unnamed-chunk-12-1.png" width="672"></p>
<p>If you want to execute a query and store the results in a temporary table, use <code>compute()</code></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">compute</span>(c4, <span class="st">'carrierhours'</span>)</code></pre></div>
<pre><code>## # Source:     lazy query [?? x 5]
## # Database:   spark_connection
## # Ordered by: carrier
##    carrier dep_delay air_time distance air_time_hours
##      &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;
##  1      AA        -7      142     1089       2.366667
##  2      AA        -9      186     1389       3.100000
##  3      AA        -6      143     1096       2.383333
##  4      AA        -4      114      733       1.900000
##  5      AA        -2      146     1085       2.433333
##  6      AA        -7      119      733       1.983333
##  7      AA        -3      193     1598       3.216667
##  8      AA        -7      137      944       2.283333
##  9      AA        -1      195     1389       3.250000
## 10      AA        -2      294     2248       4.900000
## # ... with more rows</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">src_tbls</span>(sc)</code></pre></div>
<pre><code>## [1] "airlines"     "carrierhours" "flights"</code></pre>
</div>
<div id="sql-translation" class="section level2">
<h2 class="hasAnchor">
<a href="#sql-translation" class="anchor"></a>SQL Translation</h2>
<p>It’s relatively straightforward to translate R code to SQL (or indeed to any programming language) when doing simple mathematical operations of the form you normally use when filtering, mutating and summarizing. dplyr knows how to convert the following R functions to Spark SQL:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Basic math operators</span>
<span class="op">+</span>, <span class="op">-</span>, <span class="op">*</span>, <span class="op">/</span>, <span class="op">%%</span>, <span class="op">^</span>
<span class="st">  </span>
<span class="co"># Math functions</span>
abs, acos, asin, asinh, atan, atan2, ceiling, cos, cosh, exp, floor, log, log10, round, sign, sin, sinh, sqrt, tan, tanh

<span class="co"># Logical comparisons</span>
<span class="op">&lt;</span>, <span class="op">&lt;=</span>, <span class="op">!=</span>, <span class="op">&gt;=</span>, <span class="op">&gt;</span>, <span class="op">==</span>, <span class="op">%in%</span>

<span class="co"># Boolean operations</span>
<span class="er">&amp;</span>, <span class="op">&amp;&amp;</span>, <span class="op">|</span>, <span class="op">||</span>, <span class="op">!</span>

<span class="co"># Character functions</span>
paste, tolower, toupper, nchar

<span class="co"># Casting</span>
as.double, as.integer, as.logical, as.character, as.date

<span class="co"># Basic aggregations</span>
mean, sum, min, max, sd, var, cor, cov, n</code></pre></div>
</div>
<div id="window-functions" class="section level2">
<h2 class="hasAnchor">
<a href="#window-functions" class="anchor"></a>Window Functions</h2>
<p>dplyr supports Spark SQL window functions. Window functions are used in conjunction with mutate and filter to solve a wide range of problems. You can compare the dplyr syntax to the query it has generated by using <code><a href="http://www.rdocumentation.org/packages/dbplyr/topics/sql_build">dbplyr::sql_render()</a></code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Find the most and least delayed flight each day</span>
bestworst &lt;-<span class="st"> </span>flights <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(year, month, day) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(dep_delay) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(dep_delay <span class="op">==</span><span class="st"> </span><span class="kw">min</span>(dep_delay) <span class="op">||</span><span class="st"> </span>dep_delay <span class="op">==</span><span class="st"> </span><span class="kw">max</span>(dep_delay))
dbplyr<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/dbplyr/topics/sql_build">sql_render</a></span>(bestworst)
## &lt;SQL&gt; SELECT `year`, `month`, `day`, `dep_delay`
## FROM (SELECT `year`, `month`, `day`, `dep_delay`, min(`dep_delay`) OVER (PARTITION BY `year`, `month`, `day`) AS `zzz5`, max(`dep_delay`) OVER (PARTITION BY `year`, `month`, `day`) AS `zzz6`
## FROM (SELECT `year` AS `year`, `month` AS `month`, `day` AS `day`, `dep_delay` AS `dep_delay`
## FROM `flights`) `ktzaoimsra`) `kgfvfkfiri`
## WHERE (`dep_delay` = `zzz5` OR `dep_delay` = `zzz6`)
bestworst
## # Source:   lazy query [?? x 4]
## # Database: spark_connection
## # Groups:   year, month, day
##     year month   day dep_delay
##    &lt;int&gt; &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;
##  1  2013     1     1       853
##  2  2013     1     1       -15
##  3  2013     1     1       -15
##  4  2013     1     9      1301
##  5  2013     1     9       -17
##  6  2013     1    24       -15
##  7  2013     1    24       329
##  8  2013     1    29       -27
##  9  2013     1    29       235
## 10  2013     2     1       -15
## # ... with more rows</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Rank each flight within a daily</span>
ranked &lt;-<span class="st"> </span>flights <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(year, month, day) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(dep_delay) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">rank =</span> <span class="kw">rank</span>(<span class="kw">desc</span>(dep_delay)))
dbplyr<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/dbplyr/topics/sql_build">sql_render</a></span>(ranked)</code></pre></div>
<pre><code>## &lt;SQL&gt; SELECT `year`, `month`, `day`, `dep_delay`, rank() OVER (PARTITION BY `year`, `month`, `day` ORDER BY `dep_delay` DESC) AS `rank`
## FROM (SELECT `year` AS `year`, `month` AS `month`, `day` AS `day`, `dep_delay` AS `dep_delay`
## FROM `flights`) `imjugtjfum`</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ranked</code></pre></div>
<pre><code>## # Source:   lazy query [?? x 5]
## # Database: spark_connection
## # Groups:   year, month, day
##     year month   day dep_delay  rank
##    &lt;int&gt; &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;int&gt;
##  1  2013     1     1       853     1
##  2  2013     1     1       379     2
##  3  2013     1     1       290     3
##  4  2013     1     1       285     4
##  5  2013     1     1       260     5
##  6  2013     1     1       255     6
##  7  2013     1     1       216     7
##  8  2013     1     1       192     8
##  9  2013     1     1       157     9
## 10  2013     1     1       155    10
## # ... with more rows</code></pre>
</div>
<div id="peforming-joins" class="section level2">
<h2 class="hasAnchor">
<a href="#peforming-joins" class="anchor"></a>Peforming Joins</h2>
<p>It’s rare that a data analysis involves only a single table of data. In practice, you’ll normally have many tables that contribute to an analysis, and you need flexible tools to combine them. In dplyr, there are three families of verbs that work with two tables at a time:</p>
<ul>
<li><p>Mutating joins, which add new variables to one table from matching rows in another.</p></li>
<li><p>Filtering joins, which filter observations from one table based on whether or not they match an observation in the other table.</p></li>
<li><p>Set operations, which combine the observations in the data sets as if they were set elements.</p></li>
</ul>
<p>All two-table verbs work similarly. The first two arguments are <code>x</code> and <code>y</code>, and provide the tables to combine. The output is always a new table with the same type as <code>x</code>.</p>
<p>The following statements are equivalent:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">flights <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">left_join</span>(airlines)</code></pre></div>
<pre><code>## Joining, by = "carrier"</code></pre>
<pre><code>## # Source:   lazy query [?? x 20]
## # Database: spark_connection
##     year month   day dep_time sched_dep_time dep_delay arr_time
##    &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;
##  1  2013     1     1      517            515         2      830
##  2  2013     1     1      533            529         4      850
##  3  2013     1     1      542            540         2      923
##  4  2013     1     1      544            545        -1     1004
##  5  2013     1     1      554            600        -6      812
##  6  2013     1     1      554            558        -4      740
##  7  2013     1     1      555            600        -5      913
##  8  2013     1     1      557            600        -3      709
##  9  2013     1     1      557            600        -3      838
## 10  2013     1     1      558            600        -2      753
## # ... with more rows, and 13 more variables: sched_arr_time &lt;int&gt;,
## #   arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;,
## #   origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;,
## #   minute &lt;dbl&gt;, time_hour &lt;dbl&gt;, name &lt;chr&gt;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">flights <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">left_join</span>(airlines, <span class="dt">by =</span> <span class="st">"carrier"</span>)</code></pre></div>
<pre><code>## # Source:   lazy query [?? x 20]
## # Database: spark_connection
##     year month   day dep_time sched_dep_time dep_delay arr_time
##    &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;
##  1  2013     1     1      517            515         2      830
##  2  2013     1     1      533            529         4      850
##  3  2013     1     1      542            540         2      923
##  4  2013     1     1      544            545        -1     1004
##  5  2013     1     1      554            600        -6      812
##  6  2013     1     1      554            558        -4      740
##  7  2013     1     1      555            600        -5      913
##  8  2013     1     1      557            600        -3      709
##  9  2013     1     1      557            600        -3      838
## 10  2013     1     1      558            600        -2      753
## # ... with more rows, and 13 more variables: sched_arr_time &lt;int&gt;,
## #   arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;,
## #   origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;,
## #   minute &lt;dbl&gt;, time_hour &lt;dbl&gt;, name &lt;chr&gt;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">flights <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">left_join</span>(airlines, <span class="dt">by =</span> <span class="kw">c</span>(<span class="st">"carrier"</span>, <span class="st">"carrier"</span>))</code></pre></div>
<pre><code>## # Source:   lazy query [?? x 20]
## # Database: spark_connection
##     year month   day dep_time sched_dep_time dep_delay arr_time
##    &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;
##  1  2013     1     1      517            515         2      830
##  2  2013     1     1      533            529         4      850
##  3  2013     1     1      542            540         2      923
##  4  2013     1     1      544            545        -1     1004
##  5  2013     1     1      554            600        -6      812
##  6  2013     1     1      554            558        -4      740
##  7  2013     1     1      555            600        -5      913
##  8  2013     1     1      557            600        -3      709
##  9  2013     1     1      557            600        -3      838
## 10  2013     1     1      558            600        -2      753
## # ... with more rows, and 13 more variables: sched_arr_time &lt;int&gt;,
## #   arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;,
## #   origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;,
## #   minute &lt;dbl&gt;, time_hour &lt;dbl&gt;, name &lt;chr&gt;</code></pre>
</div>
<div id="sampling" class="section level2">
<h2 class="hasAnchor">
<a href="#sampling" class="anchor"></a>Sampling</h2>
<p>You can use <code>sample_n()</code> and <code>sample_frac()</code> to take a random sample of rows: use <code>sample_n()</code> for a fixed number and <code>sample_frac()</code> for a fixed fraction.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sample_n</span>(flights, <span class="dv">10</span>)</code></pre></div>
<pre><code>## # Source:   lazy query [?? x 19]
## # Database: spark_connection
##     year month   day dep_time sched_dep_time dep_delay arr_time
##    &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;
##  1  2013     1     1      517            515         2      830
##  2  2013     1     1      533            529         4      850
##  3  2013     1     1      542            540         2      923
##  4  2013     1     1      544            545        -1     1004
##  5  2013     1     1      554            600        -6      812
##  6  2013     1     1      554            558        -4      740
##  7  2013     1     1      555            600        -5      913
##  8  2013     1     1      557            600        -3      709
##  9  2013     1     1      557            600        -3      838
## 10  2013     1     1      558            600        -2      753
## # ... with more rows, and 12 more variables: sched_arr_time &lt;int&gt;,
## #   arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;,
## #   origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;,
## #   minute &lt;dbl&gt;, time_hour &lt;dbl&gt;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sample_frac</span>(flights, <span class="fl">0.01</span>)</code></pre></div>
<pre><code>## # Source:   lazy query [?? x 19]
## # Database: spark_connection
##     year month   day dep_time sched_dep_time dep_delay arr_time
##    &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;
##  1  2013     1     1      622            630        -8     1017
##  2  2013     1     1      624            630        -6      840
##  3  2013     1     1     1155           1200        -5     1507
##  4  2013     1     1     1615           1602        13     1748
##  5  2013     1     1     2015           2005        10     2149
##  6  2013     1     2      822            823        -1     1206
##  7  2013     1     2      919            920        -1     1240
##  8  2013     1     2     1038           1035         3     1309
##  9  2013     1     2     1228           1045       103     1354
## 10  2013     1     2     1346           1350        -4     1702
## # ... with more rows, and 12 more variables: sched_arr_time &lt;int&gt;,
## #   arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;,
## #   origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;,
## #   minute &lt;dbl&gt;, time_hour &lt;dbl&gt;</code></pre>
</div>
<div id="writing-data" class="section level2">
<h2 class="hasAnchor">
<a href="#writing-data" class="anchor"></a>Writing Data</h2>
<p>It is often useful to save the results of your analysis or the tables that you have generated on your Spark cluster into persistent storage. The best option in many scenarios is to write the table out to a <a href="https://parquet.apache.org/">Parquet</a> file using the <a href="reference/sparklyr/spark_write_parquet.html">spark_write_parquet</a> function. For example:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/spark_write_parquet.html">spark_write_parquet</a></span>(tbl, <span class="st">"hdfs://hdfs.company.org:9000/hdfs-path/data"</span>)</code></pre></div>
<p>This will write the Spark DataFrame referenced by the tbl R variable to the given HDFS path. You can use the <a href="reference/sparklyr/spark_read_parquet.html">spark_read_parquet</a> function to read the same table back into a subsequent Spark session:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">tbl &lt;-<span class="st"> </span><span class="kw"><a href="../reference/spark_read_parquet.html">spark_read_parquet</a></span>(sc, <span class="st">"data"</span>, <span class="st">"hdfs://hdfs.company.org:9000/hdfs-path/data"</span>)</code></pre></div>
<p>You can also write data as CSV or JSON using the <a href="reference/sparklyr/spark_write_csv.html">spark_write_csv</a> and <a href="reference/sparklyr/spark_write_json.html">spark_write_json</a> functions.</p>
</div>
<div id="hive-functions" class="section level2">
<h2 class="hasAnchor">
<a href="#hive-functions" class="anchor"></a>Hive Functions</h2>
<p>Many of Hive’s built-in functions (UDF) and built-in aggregate functions (UDAF) can be called inside dplyr’s mutate and summarize. The <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF">Languange Reference UDF</a> page provides the list of available functions.</p>
<p>The following example uses the <strong>datediff</strong> and <strong>current_date</strong> Hive UDFs to figure the difference between the flight_date and the current system date:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">flights <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">flight_date =</span> <span class="kw">paste</span>(year,month,day,<span class="dt">sep=</span><span class="st">"-"</span>),
         <span class="dt">days_since =</span> <span class="kw">datediff</span>(<span class="kw">current_date</span>(), flight_date)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(flight_date,days_since) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">tally</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">arrange</span>(<span class="op">-</span>days_since)</code></pre></div>
<pre><code>## # Source:     lazy query [?? x 3]
## # Database:   spark_connection
## # Groups:     flight_date
## # Ordered by: -days_since
##    flight_date days_since     n
##          &lt;chr&gt;      &lt;int&gt; &lt;dbl&gt;
##  1    2013-1-1       1713   842
##  2    2013-1-2       1712   943
##  3    2013-1-3       1711   914
##  4    2013-1-4       1710   915
##  5    2013-1-5       1709   720
##  6    2013-1-6       1708   832
##  7    2013-1-7       1707   933
##  8    2013-1-8       1706   899
##  9    2013-1-9       1705   902
## 10   2013-1-10       1704   932
## # ... with more rows</code></pre>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#overview">Overview</a></li>
      <li><a href="#reading-data">Reading Data</a></li>
      <li><a href="#dplyr-verbs">dplyr Verbs</a></li>
      <li><a href="#laziness">Laziness</a></li>
      <li><a href="#piping">Piping</a></li>
      <li><a href="#grouping">Grouping</a></li>
      <li><a href="#collecting-to-r">Collecting to R</a></li>
      <li><a href="#sql-translation">SQL Translation</a></li>
      <li><a href="#window-functions">Window Functions</a></li>
      <li><a href="#peforming-joins">Peforming Joins</a></li>
      <li><a href="#sampling">Sampling</a></li>
      <li><a href="#writing-data">Writing Data</a></li>
      <li><a href="#hive-functions">Hive Functions</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Javier Luraschi, Kevin Ushey, JJ Allaire,  The Apache Software Foundation.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
